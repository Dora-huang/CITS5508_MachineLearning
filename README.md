# MachineLearning
This repository is for the unit of CITS5508 machine learning in UWA. <br>
There are some assignments I did during the study period. <br>
1. The Lab2 is about comparing the performance of the two classifiers Support Vector Classifier (SVC) and Stochastic Gradient Descent Classifier (SGDC). Besides, it also explores the impact of normalization on the model. The primary results are that the normalization play an important role in building the model and tuning hyperparameters will highly influence the accuracy of models. <br>
2. There are two parts in the Lab3. The first part is to train and evaluate the performance of a Voting classifier. Furthermore, this Voting classifier should comprise three individual classifiers: an SVM classifier, a Logistic Regression classifier and a Gradient Descent classifier. The second part is to investigate the performance of the Random Forest classifier and implement two Random Forest classifiers with different hyperparameter values. <br>
3. There are also two sections in Lab4. Implementation of AdaBoost Regressor is the first section that uses an SVM regressor with an RBF kernel as the base estimator and compares the mean square error (MSE) with Gradient Boosting Regressors with the same 6 estimators. The implement of a Random Forest regressor is the second section and compare the performance of the two versions of the regressor. <br>
4. The Lab5 is to compare the performance of Multilayer Perceptron (MLP) and Convolutional Neural Network in Deep Learning. Because they will cost lots of computing resource such as GPU, it recommends using google colab to run this jupyter notebook.  The main tasks for this lab are to design a Multilayer perceptron with two hidden layers and each hidden layer with a suitable number of neurons and an appropriate activation function. Besides, it's important to explore the different setting in the model such as learning rate, early stopping and figure out the optimal parameters by comparison of the confusion matrix. In order to explore the algorithm further, a CNN model with two convolutional layers also is designed. It needs to add pool layers and fully connected layers especially. In addition, it's similar to the MLP model experiment different parameter setting and optimising the performance of the model. 
