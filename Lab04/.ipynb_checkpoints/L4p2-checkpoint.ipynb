{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1> Lab04 sheet </h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Student ID: 22670287** <br>\n",
    "**Student Name: Xiaoyan Huang**<br>\n",
    "**Date created: 28/04/2020**<br>\n",
    "**Last modified: 4/05/2020**<br>\n",
    "\n",
    "The main goal of Project2 is to train two Random Forest Regressors using the original data and using the reduced-dimensional one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Project2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "colnames = [\"Sex\",\"Length\",\"Diameter continuous\",\"Height\",\"Whole weight\",\"Shucked weight\",\"Viscera weight\",\"Shell weight\",\"Rings\"]\n",
    "abalone = pd.read_csv(\"abalone.data\", header = None, sep = ',', names = colnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abalone.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abalone.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_index = [\"M\",\"F\",\"I\"]\n",
    "abalone['Sex'] = abalone['Sex'].apply(sex_index.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abalone.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = abalone.iloc[:,:8]\n",
    "y = abalone['Rings']\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "xlab = list(X.columns)\n",
    "ss = np.arange(len(xlab))\n",
    "plt.bar(ss, X_train.mean(axis=0))\n",
    "plt.xticks(ss, xlab, rotation = 45)\n",
    "plt.ylabel('Mean')\n",
    "plt.title('the mean of each feature')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Firstly, the categories *Sex* should be convert into numeric data 0,1 and 2.\n",
    "- The adalone data is split into training set and test set by a 85/15 proportion. There are 3550 instances in training set and 627 instances in test set.\n",
    "- From the plot, the mean of feature always between 0 and 1. Thus, there is no feature scaling in the step.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 RandomForest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rnd_clf = RandomForestRegressor(n_estimators=200, random_state=42, max_features=0.8, max_samples=3540)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prd_value_test = rnd_clf.predict(X_test)\n",
    "prd_value_train = rnd_clf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "int_prd_value_test = np.around(prd_value_test)\n",
    "int_prd_value_train = np.around(prd_value_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There are some hyperparameter values setting. For example, changing the values of *max_features* (the features are considered at each split) and *max_samples* (the number jof samples to draw from X to train each base estimator) can avoid overfitting. It could reduce the effect of outliers.\n",
    "- Since the predictive values are fraction, using `np.around` converts output into integer for both training and test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Inspect Mean Square Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mse_test = mean_squared_error(y_test,int_prd_value_test)\n",
    "print(\"Mean square error of RF model in test data is %s \" % mse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_train = mean_squared_error(y_train, int_prd_value_train)\n",
    "print(\"Mean square error of RF model in training data is %s \" % mse_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "mse_list = [mse_test, mse_train]\n",
    "xlab = ('MSE-test','MSE-train')\n",
    "ss = np.arange(len(xlab))\n",
    "plt.bar(ss, mse_list)\n",
    "plt.xticks(ss, xlab)\n",
    "plt.ylabel('MSE')\n",
    "plt.title('MSE of the predictions on training and test set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The mean square error in test set is pretty higher than training set. The average prediction *Rings* is always higher or lower by 4.7 in test set, but it is higher or lower by 0.7 in training set. However, from the range of *Rings* in the whole dataset is between 1 and 29. Perhaps it is normal to calculate the MSE more than 4. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Inspect Raw Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_test = pd.DataFrame()\n",
    "errors_train = pd.DataFrame()\n",
    "errors_test['predictive'] = int_prd_value_test\n",
    "errors_train['predictive'] = int_prd_value_train\n",
    "errors_test['y_test'] = y_test.tolist()\n",
    "errors_train['y_test'] = y_train.tolist()\n",
    "errors_test['errors'] = errors_test['predictive'] - errors_test['y_test']\n",
    "errors_train['errors'] = errors_train['predictive'] - errors_train['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_test = errors_test['errors'].value_counts()\n",
    "cnt_test = cnt_test.sort_index(ascending=True)\n",
    "cnt_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlab = cnt_test.sort_index(ascending=True).index\n",
    "ss = np.arange(len(xlab))\n",
    "plt.bar(ss, cnt_test)\n",
    "plt.xticks(ss, xlab, rotation=45)\n",
    "plt.ylabel('Count')\n",
    "plt.title('the raw errors on test set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_train = errors_train['errors'].value_counts()\n",
    "cnt_train = cnt_train.sort_index(ascending=True)\n",
    "cnt_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlab = cnt_train.index\n",
    "ss = np.arange(len(xlab))\n",
    "plt.bar(ss, cnt_train)\n",
    "plt.xticks(ss, xlab)\n",
    "plt.ylabel('MSE')\n",
    "plt.title('the prediction errors on train set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In terms of test set, the RF regressor only correctly predicts the *Rings* 149 times. There are enormous samples overestimated by one (155 times) and underestimated by one (99 times). Even worse, the RF regressor overestimated and underestimated by over 4.7 (4 times and 24 times).\n",
    "- For the training set, the RF regressor performs well. It correctly predicts the quality rating with 2086 times, and overestimates (or underestimates) the quality rating by one (or minus one) 763 times (or 471 times).\n",
    "- However, there is an extremely value -7."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 RandomForest Regressor with Reduce Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = pd.DataFrame()\n",
    "feature_list['name'] = colnames[:8]\n",
    "feature_list['value'] = rnd_clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = feature_list.sort_values(by = \"value\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 0\n",
    "new_feature = []\n",
    "for i in range(0, len(feature_list.iloc[:,1])):\n",
    "    if s < 0.95:\n",
    "        s = s + feature_list.iloc[i,1]\n",
    "        new_feature.append(feature_list.iloc[i,0])\n",
    "new_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_rd = X_test.loc[:,new_feature]\n",
    "X_train_rd = X_train.loc[:,new_feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_rd.shape, X_train_rd.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using a loop retains just over 95% of the feature importance. And here, the feature *Sex* is removed due to low feature importance.\n",
    "- The variable *new_feature* is created, which uses to build a new RF regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd_rnd_clf = RandomForestRegressor(n_estimators=150, random_state=42, max_depth=30, max_features=0.8, max_samples=3540)\n",
    "rd_rnd_clf.fit(X_train_rd, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd_prd_value_test = rd_rnd_clf.predict(X_test_rd)\n",
    "rd_prd_value_train = rd_rnd_clf.predict(X_train_rd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd_int_prd_test = np.around(rd_prd_value_test)\n",
    "rd_int_prd_train = np.around(rd_prd_value_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The new RF regressor with reducing the feature dimension is built `rd_rnd_clf`. \n",
    "- Some hyperparameters are reset. The value of *n_estimators* (the number of trees in the forest) should be decreased because the performance of previous model is not good in test set. Besides, other hyperparameters retain the same value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1 Inspect Mean Square Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd_mse_test = mean_squared_error(y_test, rd_int_prd_test)\n",
    "print(\"Mean square error of final model in test data is %s \" % rd_mse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd_mse_train = mean_squared_error(y_train, rd_int_prd_train)\n",
    "print(\"Mean square error of final model in training data is %s \" % rd_mse_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_list = [rd_mse_test, rd_mse_train]\n",
    "xlab = ('MSE-test','MSE-train')\n",
    "ss = np.arange(len(xlab))\n",
    "plt.bar(ss, mse_list)\n",
    "plt.xticks(ss, xlab)\n",
    "plt.ylabel('MSE')\n",
    "plt.title('MSE of the predictions on training and test set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The mean square error in test set and training set both increases slightly. And the average prediction Rings is always higher or lower by 4.9 in test set. In terms of MSE, the performances of both regressors are similar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 Inspect Raw Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd_errors_test = pd.DataFrame()\n",
    "rd_errors_train = pd.DataFrame()\n",
    "rd_errors_test['predictive'] = rd_int_prd_test\n",
    "rd_errors_train['predictive'] = rd_int_prd_train\n",
    "rd_errors_test['y_test'] = y_test.tolist()\n",
    "rd_errors_train['y_test'] = y_train.tolist()\n",
    "rd_errors_test['errors'] = rd_errors_test['predictive'] - rd_errors_test['y_test']\n",
    "rd_errors_train['errors'] = rd_errors_train['predictive'] - rd_errors_train['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_test2 = rd_errors_test['errors'].value_counts()\n",
    "cnt_test2 = cnt_test2.sort_index(ascending=True)\n",
    "cnt_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlab = cnt_test2.index\n",
    "ss = np.arange(len(xlab))\n",
    "plt.bar(ss, cnt_test2)\n",
    "plt.xticks(ss, xlab, rotation=45)\n",
    "plt.ylabel('Count')\n",
    "plt.title('the raw errors on train set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_train2 = rd_errors_train['errors'].value_counts()\n",
    "cnt_train2 = cnt_train2.sort_index(ascending=True)\n",
    "cnt_train2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlab = cnt_train2.index\n",
    "ss = np.arange(len(xlab))\n",
    "plt.bar(ss, cnt_train2)\n",
    "plt.xticks(ss, xlab)\n",
    "plt.ylabel('Count')\n",
    "plt.title('the raw errors on train set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In terms of test set, although the RF regressor correctly predicts the Rings 156 times, it is higher than previous one (149 times). The second regressor avoids overfitting to slightly increase the accuracy, even though there are still enormous samples overestimated by one (150 times) and underestimated by one (88 times). Besides, the number of samples overestimated (and underestimated) by over 4.8 (and -4.8) are 4 times (and 26 times).\n",
    "- For the training set, the RF regressor performs not as good as the previous one. It correctly predicts the quality rating with 2058 times (2086 in the first regressor), and overestimates (or underestimates) the quality rating by one (or minus one) 790 times (or 472 times).\n",
    "- However, there is an extremely value -12 in test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_list = [mse_test, mse_train,rd_mse_test, rd_mse_train]\n",
    "xlab = ('MSE-test','MSE-train','MSE-test-rd','MSE-train-rd')\n",
    "ss = np.arange(len(xlab))\n",
    "plt.bar(ss, mse_list)\n",
    "plt.xticks(ss, xlab)\n",
    "plt.ylabel('MSE')\n",
    "plt.title('MSE of the predictions on training and test set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For **MSEs**, there are slightly increase after reducing dimension. In terms of **raws error**, the second RF regressor correctly predicts the Rings 156 times higher than the previous one (149 times) and the accuracy increases slightly. But, it also appears extremely error value like -12 in the test set. Thus, there's a tradeoff."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
