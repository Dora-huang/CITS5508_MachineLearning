{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Lab03 sheet</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Student ID: 22670287** <br>\n",
    "**Student Name: Xiaoyan Huang**<br>\n",
    "**Create Data: 7/4/2020**<br>\n",
    "**End Data: 8/4/2020**<br>\n",
    "\n",
    "Project2 is to train and test two Random Forest classifiers and compares them in accuracy and F1 score via a Parkinsons dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Project2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pk = pd.read_csv(\"parkinsons.data\", sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pk['status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "pk.iloc[:,[4,5,6,7,8]].hist(bins = 50, figsize = (20,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pk.iloc[:,[9,10,11,12,13,14]].hist(bins = 50, figsize = (20,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pk.iloc[:,[15,16]].hist(bins = 30, figsize = (20,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pk.iloc[:,[18,22]].hist(bins = 50, figsize = (20,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pk.iloc[:,[20,21,23]].hist(bins = 50, figsize = (20,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There are 23 attributes and one label with 195 instances. From the attribute information, we know some attributes have same meaning and it is necessary to remove the redundant attributes.\n",
    "- MDVP:Jitter(%),MDVP:Jitter(Abs),MDVP:RAP,MDVP:PPQ,Jitter:DDP(Several measures of variation in fundamental frequency), these measures have the same patterns from histogram. MDVP:Jitter is picked up to represent the variation.\n",
    "- MDVP:Shimmer,MDVP:Shimmer(dB),Shimmer:APQ3,Shimmer:APQ5,MDVP:APQ,Shimmer:DDA are measures of variation in amplitude with the same patterns. MDVP:Shimmer is kept.\n",
    "- NHR,HNR are two measures of ratio of noise to tonal components in the voice. But they show different pattern from histogram. Thus, both measures are kept.\n",
    "- RPDE and PPE are saved due to same reason."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pks_X = pk.iloc[:,[1,2,3,4,9,15,16,18,19,23]]\n",
    "pks_y = pk.iloc[:,17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pks_X.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- After feature selection, there are 10 attributes reserved.\n",
    "- From the description of *pks_X*, the ranges among features are different. Intuitively, it needs to normalize the data before build model. In the next step, *X_train* and *X_train_nm* are created to explore the effect of normalization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Split data into train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(pks_X, pks_y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "X_train_nm = preprocessing.normalize(X_train)\n",
    "X_test_nm = preprocessing.normalize(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_nm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The dataset was splited into training set with 156 instances and testing set with 39 instances. \n",
    "- *X_train* and *X_train_nm*, *X_test* and *X_test_nm* are contrast group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Build RandomForest classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rnd_clf = RandomForestClassifier(random_state=42)\n",
    "rnd_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "y_pred_rf = rnd_clf.predict(X_test)\n",
    "print(\"It is f1 score of random forest without normalization: %s\" % metrics.f1_score(y_test, y_pred_rf, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"It is accuracy of random forest without normalization: %s\" % rnd_clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_clf_nm = RandomForestClassifier(random_state=42)\n",
    "rnd_clf_nm.fit(X_train_nm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf_nm = rnd_clf_nm.predict(X_test_nm)\n",
    "print(\"It is f1 score of random forest with normalization: %s\" % metrics.f1_score(y_test, y_pred_rf_nm, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"It is accuracy of random forest with normalization: %s\" % rnd_clf_nm.score(X_test_nm, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- *rnd_clf_nm* is a default model trained by the normalized data; *rnd_clf* is also a default model trained by untreated data.\n",
    "\n",
    "- The performance of *rnd_clf_nm* is better with a higer accuracy, which illustrates that it is necessay to normalize the data which can improve the accuracy.\n",
    "\n",
    "- F1 score is the weighted average of Precision and Recall. Thus, F1 score should be closed to 1 and the second model is better reaching 90.1%\n",
    "\n",
    "- In the next step, *rnd_clf_nm2* with different hyperparameter values are created to compare with *rnd_clf_nm* the default one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_clf_nm2 = RandomForestClassifier(random_state=42, class_weight=\"balanced\", n_estimators=800)\n",
    "rnd_clf_nm2.fit(X_train_nm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf_nm2 = rnd_clf_nm2.predict(X_test_nm)\n",
    "print(\"It is the accuracy of the second classifier: %s\" % rnd_clf_nm2.score(X_test_nm, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf_nm2 = rnd_clf_nm2.predict(X_test_nm)\n",
    "print(\"It is the f1 scores of the second classifier: %s\" % metrics.f1_score(y_test, y_pred_rf_nm2, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The accuracy and F1 Score don't increase after changing the values of n_estimators and class_weight.\n",
    "- The training set with normalization plays an important role in this situation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
